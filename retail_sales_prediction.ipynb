{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d45050da",
   "metadata": {},
   "source": [
    "# üõí Retail Sales Prediction Project\n",
    "### End-to-End Machine Learning Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c550ec",
   "metadata": {},
   "source": [
    "\n",
    "## üìå Overview  \n",
    "This project follows a complete **ML pipeline** from data preprocessing to model training and deployment using Flask & Docker.  \n",
    "\n",
    "### üî• Steps Covered:  \n",
    "1Ô∏è‚É£ Data Cleaning & Exploration  \n",
    "2Ô∏è‚É£ Model Training & Evaluation  \n",
    "3Ô∏è‚É£ Save the Model (`.pkl` file)  \n",
    "4Ô∏è‚É£ Build a Flask API for Predictions  \n",
    "5Ô∏è‚É£ Deploy using Docker üöÄ  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81be153",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üìö Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380a95a1",
   "metadata": {},
   "source": [
    "## üìÇ Load & Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d2443",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Dataset\n",
    "file_path = \"Warehouse_and_Retail_Sales.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Show dataset info\n",
    "df.info(), df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271cc31",
   "metadata": {},
   "source": [
    "## üßπ Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d419c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle missing values\n",
    "df[\"SUPPLIER\"].fillna(\"UNKNOWN_SUPPLIER\", inplace=True)\n",
    "df[\"ITEM TYPE\"].fillna(\"UNKNOWN_TYPE\", inplace=True)\n",
    "df[\"RETAIL SALES\"].fillna(df[\"RETAIL SALES\"].median(), inplace=True)\n",
    "\n",
    "# Confirm no missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921d45cc",
   "metadata": {},
   "source": [
    "## üìä Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot sales distributions\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.histplot(df[\"RETAIL SALES\"], bins=50, kde=True, ax=axes[0], color=\"blue\")\n",
    "axes[0].set_title(\"Retail Sales Distribution\")\n",
    "\n",
    "sns.histplot(df[\"RETAIL TRANSFERS\"], bins=50, kde=True, ax=axes[1], color=\"green\")\n",
    "axes[1].set_title(\"Retail Transfers Distribution\")\n",
    "\n",
    "sns.histplot(df[\"WAREHOUSE SALES\"], bins=50, kde=True, ax=axes[2], color=\"red\")\n",
    "axes[2].set_title(\"Warehouse Sales Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44289e41",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Feature Engineering & Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe948e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature Selection\n",
    "features = [\"YEAR\", \"MONTH\", \"SUPPLIER\", \"ITEM TYPE\", \"RETAIL TRANSFERS\", \"WAREHOUSE SALES\"]\n",
    "target = \"RETAIL SALES\"\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in [\"SUPPLIER\", \"ITEM TYPE\"]:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Train-Test Split (10% for training due to memory constraints)\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=42)\n",
    "\n",
    "# Train Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "mae_lr, mse_lr, r2_lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9c31d",
   "metadata": {},
   "source": [
    "## üíæ Save Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the trained model as a pickle file\n",
    "model_filename = \"retail_sales_model.pkl\"\n",
    "with open(model_filename, \"wb\") as file:\n",
    "    pickle.dump(lr_model, file)\n",
    "\n",
    "print(f\"Model saved as {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e596180a",
   "metadata": {},
   "source": [
    "## üöÄ Flask API for Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8888b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load Model\n",
    "with open(\"retail_sales_model.pkl\", \"rb\") as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Initialize Flask App\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return \"Retail Sales Prediction API is Running!\"\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    features = np.array([\n",
    "        data[\"YEAR\"], data[\"MONTH\"], data[\"SUPPLIER\"], \n",
    "        data[\"ITEM TYPE\"], data[\"RETAIL TRANSFERS\"], data[\"WAREHOUSE SALES\"]\n",
    "    ]).reshape(1, -1)\n",
    "    prediction = model.predict(features)[0]\n",
    "    return jsonify({\"predicted_retail_sales\": round(prediction, 2)})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000, debug=True)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484721cb",
   "metadata": {},
   "source": [
    "## üê≥ Dockerize Flask API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "# Use Python base image\n",
    "FROM python:3.9\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy files to container\n",
    "COPY . /app\n",
    "\n",
    "# Install dependencies\n",
    "RUN pip install flask numpy pandas scikit-learn\n",
    "\n",
    "# Expose port\n",
    "EXPOSE 5000\n",
    "\n",
    "# Run Flask app\n",
    "CMD [\"python\", \"app.py\"]\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}